{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_references(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    references_started = False\n",
    "    references_text = \"\"\n",
    "\n",
    "    # Iterate over each page in the PDF\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "\n",
    "        # Check for the start of the references section (commonly starts with 'References' or 'Bibliography')\n",
    "        if not references_started:\n",
    "            if \"References\" in text or \"Bibliography\" or \"REFERENCES\" in text:\n",
    "                references_started = True\n",
    "                references_text += text  # Start collecting references from this page\n",
    "        else:\n",
    "            references_text += text  # Continue collecting references after it starts\n",
    "\n",
    "    return references_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text-to-SQL based on Large Language Models and Database Keyword\n",
      "Search\n",
      "Eduardo R. Nascimento1, Caio Viktor S. Avila1,4, Yenier T. Izquierdo1, Grettel M. Garc´ıa1, Lucas\n",
      "Feij´o L. Andrade1, Michelle S.P. Facina2, Melissa Lemos1, Marco A. Casanova1,3\n",
      "1 Instituto Tecgraf, PUC-Rio, Rio de Janeiro, RJ, Brazil CEP 22451-900\n",
      "2 Petrobras, Rio de Janeiro, RJ, Brazil CEP 20231-030\n",
      "3 Departamento de Inform´atica, PUC-Rio, Rio de Janeiro, RJ, Brazil CEP 22451-900\n",
      "4 Departamento de Computac¸˜ao, UFC, Fortaleza, Brazil, CEP 60440-900\n",
      "{rogerrsn,ytorres,ggarcia,lucasfeijo,melissa}@tecgraf.puc-rio.br, caioviktor@alu.ufc.br, michelle@petrobras.com.br,\n",
      "casanova@inf.puc-rio.br\n",
      "Keywords:\n",
      "Text-to-SQL, Database Keyword Search, Large Language Models, Relational Databases.\n",
      "Abstract:\n",
      "Text-to-SQL prompt strategies based on Large Language Models (LLMs) achieve remarkable performance on\n",
      "well-known benchmarks. However, when applied to real-world databases, their performance is significantly\n",
      "less than for these benchmarks, especially for Natural Language (NL) questions requiring complex filters\n",
      "and joins to be processed. This paper then proposes a strategy to compile NL questions into SQL queries\n",
      "that incorporates a dynamic few-shot examples strategy and leverages the services provided by a database\n",
      "keyword search (KwS) platform. The paper details how the precision and recall of the schema-linking process\n",
      "are improved with the help of the examples provided and the keyword-matching service that the KwS platform\n",
      "offers. Then, it shows how the KwS platform can be used to synthesize a view that captures the joins required\n",
      "to process an input NL question and thereby simplify the SQL query compilation step. The paper includes\n",
      "experiments with a real-world relational database to assess the performance of the proposed strategy. The\n",
      "experiments suggest that the strategy achieves an accuracy on the real-world relational database that surpasses\n",
      "state-of-the-art approaches. The paper concludes by discussing the results obtained.\n",
      "1\n",
      "INTRODUCTION\n",
      "The Text-to-SQL task is defined as “given a relational\n",
      "database D and a natural language (NL) sentence\n",
      "QN that describes a question on D, generate an SQL\n",
      "query QSQL over D that expresses QN” (Katsogiannis-\n",
      "Meimarakis and Koutrika, 2023; Kim et al., 2020).\n",
      "Numerous tools have addressed this task with rel-\n",
      "ative success (Affolter et al., 2019; Katsogiannis-\n",
      "Meimarakis and Koutrika, 2023; Kim et al., 2020;\n",
      "Shi et al., 2024) over well-known benchmarks, such\n",
      "as Spider – Yale Semantic Parsing and Text-to-SQL\n",
      "Challenge (Yu et al., 2018) and BIRD – BIg Bench for\n",
      "LaRge-scale Database Grounded Text-to-SQL Eval-\n",
      "uation (Li et al., 2024). The leaderboards of these\n",
      "benchmarks point to a firm trend: the best text-to-\n",
      "SQL tools are all based on Large Language Models\n",
      "(LLMs) (Shi et al., 2024).\n",
      "Text-to-SQL tools must face several challenges.\n",
      "To begin with, they must be able to process NL ques-\n",
      "tions that require multiple SQL constructs (Yu et al.,\n",
      "2018). For example, processing the NL question:\n",
      "“Which has more open orders, P-X or P-Y?”\n",
      "requires:\n",
      "• Recognizing that P-X and P-Y are industrial in-\n",
      "stallations;\n",
      "• Joining installations and orders;\n",
      "• Understanding what is an open order;\n",
      "• Computing the number of open orders for each of\n",
      "the installations.\n",
      "• Returning the installation with the largest number\n",
      "of open orders.\n",
      "Omitting the details, the following SQL query\n",
      "would answer the above NL question:\n",
      "SELECT t.name ,\n",
      "COUNT(*) AS number_open_orders\n",
      "FROM Installation t JOIN Order o\n",
      "ON t.code = o.installation_code\n",
      "WHERE (t.name = 'P-X' OR t.name = 'P-Y')\n",
      "arXiv:2501.13594v1  [cs.DB]  23 Jan 2025\n",
      "AND LOWER(o.status) LIKE LOWER ('%Open%')\n",
      "GROUP BY t.code\n",
      "ORDER BY number_open_orders DESC\n",
      "FETCH 1\n",
      "This is an example of a challenging NL question\n",
      "that the strategy proposed in this paper can compile\n",
      "into a correct SQL query.\n",
      "In addition, real-world databases raise a different\n",
      "set of challenges for several reasons, among which:\n",
      "1. The relational schema is often large, in the num-\n",
      "ber of tables, columns per table, and foreign keys\n",
      "– which may lead to queries with many joins,\n",
      "which are difficult to synthesize.\n",
      "2. The relational schema is often an inappropriate\n",
      "specification of the database from the point of\n",
      "view of the LLM – the table and column names\n",
      "are often different from the terms the users adopt\n",
      "to formulate their NL questions.\n",
      "3. The data semantics are often complex; for ex-\n",
      "ample, some data values may encode enumerated\n",
      "domains, which implies that the terms the users\n",
      "adopt to formulate their NL questions must be\n",
      "mapped to this internal semantics.\n",
      "4. Metadata and data are often ambiguous, which in-\n",
      "fluences the behavior of an LLM-based text-to-\n",
      "SQL tool, leading to unexpected results.\n",
      "Indeed, the performance of some of the best LLM-\n",
      "based text-to-SQL tools on real-world databases is\n",
      "significantly less than that observed for the Spider\n",
      "and BIRD benchmarks (Nascimento et al., 2024a; Lei\n",
      "et al., 2024).\n",
      "This paper then addresses the real-world text-to-\n",
      "SQL problem, which is the version of the text-to-SQL\n",
      "problem for real-world databases. Albeit the origi-\n",
      "nal problem has been investigated for some time, this\n",
      "version is considered far from solved, as argued in\n",
      "(Floratou et al., 2024; Lei et al., 2024).\n",
      "The first contribution of the paper is a novel\n",
      "strategy to compile NL questions into SQL queries\n",
      "that leverages the services provided by a database\n",
      "keyword search (KwS) platform, called DANKE\n",
      "(Izquierdo et al., 2021; Izquierdo et al., 2024). The\n",
      "proposed strategy is the first one to explore a sym-\n",
      "biotic combination of a KwS platform and a prompt\n",
      "strategy to process NL questions.\n",
      "Briefly, Section 4.3 details how the combination\n",
      "of DANKE’s data dictionary with a dynamic few-shot\n",
      "examples strategy improves the precision and recall\n",
      "of the schema-linking process, that is, the process of\n",
      "finding a set of tables that suffice to compile an in-\n",
      "put NL question. Then, Section 4.4 shows how the\n",
      "SQL query compilation step is also improved by call-\n",
      "ing DANKE to synthesize a view V that captures the\n",
      "required joins to answer the input NL question QN,\n",
      "and then calling an LLM to compile QN into an SQL\n",
      "query QSQL over V, which can be remapped to the\n",
      "database schema with the help of the definition of V.\n",
      "The second contribution of the paper is a set of\n",
      "experiments with a real-world benchmark to assess\n",
      "the performance of the proposed strategy. The bench-\n",
      "mark is built upon a relational database with a chal-\n",
      "lenging schema, which is in production at an en-\n",
      "ergy company, and a set of 100 NL questions care-\n",
      "fully defined to reflect the NL questions users submit\n",
      "and to cover a wide range of SQL constructs (Spi-\n",
      "der and BIRD, two of the familiar text-to-SQL bench-\n",
      "marks, were not adopted for the reasons explained in\n",
      "Section 2.1). These new results, combined with re-\n",
      "sults from (Nascimento et al., 2024a), indicate that\n",
      "the proposed strategy performs significantly better\n",
      "on the real-world benchmark than LangChain SQL-\n",
      "QueryChain, SQLCoder1, “C3 + ChatGPT + Zero-\n",
      "Shot” (Dong et al., 2023), and “DIN-SQL + GPT-4”\n",
      "(Pourreza and Rafiei, 2024).\n",
      "This paper is an extended version of (Nascimento\n",
      "et al., 2025).\n",
      "The paper is organized as follows. Section 2 cov-\n",
      "ers related work. Section 3 describes the database\n",
      "keyword search platform adopted in the paper. Sec-\n",
      "tion 4 details the proposed text-to-SQL strategy. Sec-\n",
      "tion 5 presents the experiments, including the real-\n",
      "world benchmark used. Finally, Section 6 contains\n",
      "the conclusions.\n",
      "2\n",
      "RELATED WORK\n",
      "2.1\n",
      "Text-to-SQL Datasets\n",
      "The Spider – Yale Semantic Parsing and Text-to-SQL\n",
      "Challenge (Yu et al., 2018) defines 200 datasets, cov-\n",
      "ering 138 different domains, for training and testing\n",
      "text-to-SQL tools.\n",
      "For each database, Spider lists 20–50 hand-written\n",
      "NL questions and their SQL translations.\n",
      "An NL\n",
      "question S, with an SQL translation QN, is classi-\n",
      "fied as easy, medium, hard, and extra-hard, where the\n",
      "difficulty is based on the number of SQL constructs\n",
      "of QN – GROUP BY, ORDER BY, INTERSECT, nested\n",
      "sub-queries, column selections, and aggregators – so\n",
      "that an NL query whose translation QN contains more\n",
      "SQL constructs is considered more complex. The set\n",
      "of NL questions introduced in Section 5.1.2 follows\n",
      "this classification, but does not consider extra-hard\n",
      "NL questions.\n",
      "1https://huggingface.co/defog/sqlcoder-34b-alpha\n",
      "Spider proposes three evaluation metrics: compo-\n",
      "nent matching checks whether the components of the\n",
      "prediction and the ground-truth SQL queries match\n",
      "exactly; exact matching measures whether the pre-\n",
      "dicted SQL query as a whole is equivalent to the\n",
      "ground-truth SQL query; execution accuracy requires\n",
      "that the predicted SQL query selects a list of gold val-\n",
      "ues and fills them into the correct slots. Section 5.2\n",
      "describes the metric used in the experiments of this\n",
      "paper, which is a variation of execution accuracy.\n",
      "Most databases in Spider have very small schemas\n",
      "– the largest five databases have between 16 and 25\n",
      "tables, and about half have schemas with five tables\n",
      "or fewer. Furthermore, all Spider NL questions are\n",
      "phrased in terms used in the database schemas. These\n",
      "two limitations considerably reduce the difficulty of\n",
      "the text-to-SQL task. Therefore, the results reported\n",
      "in the Spider leaderboard are biased toward databases\n",
      "with small schemas and NL questions written in the\n",
      "schema vocabulary, which is not what one finds in\n",
      "real-world databases.\n",
      "Spider has two interesting variations. Spider-Syn\n",
      "(Gan et al., 2021a) is used to test how well text-to-\n",
      "SQL tools handle synonym substitution, and Spider-\n",
      "DK (Gan et al., 2021b) addressed testing how well\n",
      "text-to-SQL tools deal with domain knowledge.\n",
      "BIRD – BIg Bench for LaRge-scale Database\n",
      "Grounded Text-to-SQL Evaluation (Li et al., 2024)\n",
      "is a large-scale, cross-domain text-to-SQL benchmark\n",
      "in English. The dataset contains 12,751 text-to-SQL\n",
      "data pairs and 95 databases with a total size of 33.4\n",
      "GB across 37 domains. However, BIRD still does not\n",
      "have many databases with large schemas – of the 73\n",
      "databases in the training dataset, only two have more\n",
      "than 25 tables, and, of the 11 databases used for de-\n",
      "velopment, the largest one has only 13 tables. Again,\n",
      "all NL questions are phrased in the terms used in the\n",
      "database schemas.\n",
      "Finally, the sql-create-context2 dataset also\n",
      "addresses the text-to-SQL task, and was built from\n",
      "WikiSQL and Spider. It contains 78,577 examples of\n",
      "NL questions, SQL CREATE TABLE statements, and\n",
      "SQL queries answering the questions. The CREATE\n",
      "TABLE statement provides context for the LLMs, with-\n",
      "out having to provide actual rows of data.\n",
      "Despite the availability of these benchmark\n",
      "datasets for the text-to-SQL task, and inspired by\n",
      "them, Section 5.1 describes a benchmark dataset con-\n",
      "structed specifically to test strategies designed for the\n",
      "real-world text-to-SQL task. The benchmark dataset\n",
      "consists of a relational database, three sets of LLM-\n",
      "friendly views, specified as described in Section 5.1.3,\n",
      "2https://huggingface.co/datasets/b-mc2/\n",
      "sql-create-context\n",
      "and a set of 100 test NL questions and their ground-\n",
      "truth SQL translations. The database schema is in-\n",
      "spired by a real-world schema and is far more chal-\n",
      "lenging than most of the database schemas available\n",
      "in Spider or BIRD. The database is populated with\n",
      "real data with a semantics which is sometimes not\n",
      "easily mapped to the semantics of the terms the users\n",
      "adopt (such as “criticity level = 5” encodes “critical\n",
      "orders”), which is a challenge for the text-to-SQL task\n",
      "not captured by unpopulated databases, as in Spider.\n",
      "Finally, the NL questions mimic those posed by real\n",
      "users, and cover a wide range of SQL constructs (see\n",
      "Table 1 in Section 5.1.2).\n",
      "2.2\n",
      "Text-to-SQL Tools\n",
      "A comprehensive survey of text-to-SQL strategies can\n",
      "be found in (Shi et al., 2024), including a discussion\n",
      "of benchmark datasets, prompt engineering, and fine-\n",
      "tuning methods, partly covered in what follows.\n",
      "The Spider Web site3 publishes a leaderboard with\n",
      "the best-performing text-to-SQL tools. At the time\n",
      "of this writing, the top 5 tools achieved an accuracy\n",
      "that ranged from an impressive 85.3% to 91.2% (two\n",
      "of the tools are not openly documented). Four tools\n",
      "use GPT-4, as their names imply.\n",
      "The three tools\n",
      "that provide detailed documentation have an elaborate\n",
      "first prompt that tries to select the tables and columns\n",
      "that best match the NL question. Therefore, this first\n",
      "prompt is prone to failure if the database schema in-\n",
      "duces a vocabulary disconnected from the NL ques-\n",
      "tion terms. This failure cannot be fixed by even more\n",
      "elaborate prompts that try to match the schema and\n",
      "the NL question vocabularies, but it should be ad-\n",
      "dressed as proposed in this paper.\n",
      "The BIRD Web site4 also publishes a leaderboard\n",
      "with the best-performing tools. At the time of this\n",
      "writing, out of the top 5 tools, two use GPT-4, one\n",
      "uses CodeS-15B, one CodeS-7B, and one is not doc-\n",
      "umented. The sixth and seventh tools also use GPT-\n",
      "4, appear in the Spider leaderboard, and are well-\n",
      "documented.\n",
      "The Awesome Text2SQL Web site5 lists the best-\n",
      "performing text-to-SQL tools on WikiSQL, Spider\n",
      "(Exact Match and Exact Execution) and BIRD (Valid\n",
      "Efficiency Score and Execution Accuracy).\n",
      "The DB-GPT-Hub6 is a project exploring how to\n",
      "use LLMs for text-to-SQL. It contains data collection,\n",
      "data preprocessing, model selection and building, and\n",
      "3https://yale-lily.github.io/spider\n",
      "4https://bird-bench.github.io\n",
      "5https://github.com/eosphoros-ai/Awesome-Text2SQL\n",
      "6https://github.com/eosphoros-ai/DB-GPT-Hub\n",
      "fine-tuning weights, including LLaMA-2, and evalu-\n",
      "ating several LLMs fine-tuned for text-to-SQL.\n",
      "Several text-to-SQL tools were tested in (Nasci-\n",
      "mento et al., 2024a) against the benchmark used in\n",
      "this paper – SQLCoder, LangChain SQLQueryChain,\n",
      "C3, and DIN+SQL.\n",
      "SQLCoder7 is a specialized text-to-SQL model,\n",
      "open-sourced under the Apache-2 license.\n",
      "The\n",
      "sqlcoder-34b-alpha model features 34B parameters\n",
      "and was fine-tuned on a base CodeLlama model, on\n",
      "more than 20,000 human-curated questions, classified\n",
      "as in Spider, based on ten different schemas.\n",
      "LangChain8 is a generic framework that offers\n",
      "several pre-defined strategies to build and run SQL\n",
      "queries based on NL prompts.\n",
      "“C3 + ChatGPT + Zero-Shot” (Dong et al., 2023)\n",
      "(or briefly C3) is a prompt-based strategy, originally\n",
      "defined for ChatGPT, that uses only approximately\n",
      "1,000 tokens per query and achieves a better perfor-\n",
      "mance than fine-tuning-based methods. C3 has three\n",
      "key components: Clear Prompting (CP); Calibration\n",
      "with Hints (CH); Consistent Output (CO). At the time\n",
      "of writing, C3 was the sixth strategy listed in the Spi-\n",
      "der leaderboard, achieving 82.3% in terms of execu-\n",
      "tion accuracy on the test set. It outperformed state-\n",
      "of-the-art fine-tuning-based approaches in execution\n",
      "accuracy on the test set.\n",
      "“DIN-SQL + GPT-4” (Pourreza and Rafiei, 2024)\n",
      "(or briefly DIN) uses only prompting techniques and\n",
      "decomposes the text-to-SQL task into four steps:\n",
      "schema linking; query classification and decomposi-\n",
      "tion; SQL generation; and self-correction. When re-\n",
      "leased, DIN was the top-performing tool listed in the\n",
      "Spider leaderboard, achieving 85.3% in terms of exe-\n",
      "cution accuracy.\n",
      "Despite the impressive results of C3 and DIN on\n",
      "Spider, and of SQLCoder on a specific benchmark,\n",
      "the performance of these tools on the benchmark used\n",
      "in this paper was significantly lower (Nascimento\n",
      "et al., 2024a), and much less than that of the strat-\n",
      "egy described in Section 4.\n",
      "A similar remark ap-\n",
      "plies to LangChain SQLQueryChain, whose results\n",
      "are shown in Line 1 of Table 3.\n",
      "2.3\n",
      "Retrieval-Augmented and Dynamic\n",
      "Few-shot Examples Prompting\n",
      "Retrieval-Augmented Generation (RAG), introduced\n",
      "in (Lewis et al., 2020), is a strategy to incorporate data\n",
      "from external sources. This process ensures that the\n",
      "responses are grounded in retrieved evidence, thereby\n",
      "7https://huggingface.co/defog/sqlcoder-34b-alpha\n",
      "8https://python.langchain.com\n",
      "significantly enhancing the accuracy and relevance of\n",
      "the output. There is an extensive literature on RAG.\n",
      "A recent survey (Gao et al., 2024) classified RAG\n",
      "strategies into naive, advanced, and modular RAG.\n",
      "Naive RAG follows the traditional process that in-\n",
      "cludes indexing, retrieval, and generation of docu-\n",
      "ment “chunks”. Advanced RAG introduces various\n",
      "methods to optimize retrieval. Modular RAG inte-\n",
      "grates strategies to enhance functional modules, such\n",
      "as incorporating a search module for similarity re-\n",
      "trieval and applying a fine-tuning approach in the re-\n",
      "triever.\n",
      "As for text-to-SQL, recent references include a\n",
      "RAG technique (Panda and Gozluklu, 2024) to re-\n",
      "trieve table and column descriptions from a metadata\n",
      "store that are related to the NL question, based on sim-\n",
      "ilarity search.\n",
      "LangChain offers a dynamic few-shot examples\n",
      "prompting technique9 also based on similarity search.\n",
      "Given an NL question QN, the prompting strategy in-\n",
      "cludes the examples most relevant to QN, retrieved by\n",
      "a similarity search between QN and a set of examples\n",
      "previously stored in a vector database.\n",
      "A retrieval-augmented prompting method for a\n",
      "LLM-based text-to-SQL framework is proposed in\n",
      "(Guo et al., 2024), involving sample-aware prompting\n",
      "and a dynamic revision chain. The method uses two\n",
      "strategies to retrieve questions sharing similar intents\n",
      "with input questions. Firstly, using LLMs, the method\n",
      "simplifies the original questions, unifying the syntax\n",
      "and thereby clarifying the users’ intentions. To gener-\n",
      "ate executable and accurate SQL queries without hu-\n",
      "man intervention, the method incorporates a dynamic\n",
      "revision chain, which iteratively adapts fine-grained\n",
      "feedback from the previously generated SQL queries.\n",
      "A similar strategy is proposed in (Coelho et al.,\n",
      "2024), that also describes a technique to create syn-\n",
      "thetic datasets with sets of examples (Q,S) where QN\n",
      "is an NL question and S is its SQL translation.\n",
      "3\n",
      "A DATABASE KEYWORD\n",
      "QUERY PROCESSING TOOL\n",
      "DANKE is the keyword search platform currently de-\n",
      "ployed for the industrial database described in Sec-\n",
      "tion 5.1 and used for the experiments. The reader is\n",
      "referred to (Izquierdo et al., 2021; Izquierdo et al.,\n",
      "2024) for the details of the platform.\n",
      "DANKE operates over both relational databases\n",
      "and RDF datasets, and is designed to compile a key-\n",
      "9https://python.langchain.com/v0.1/docs/use cases/sql/\n",
      "prompting/\n",
      "word query into an SQL or SPARQL query that re-\n",
      "turns the best data matches. For simplicity, the de-\n",
      "scription that follows uses the relational terminology.\n",
      "DANKE’s architecture comprises three main com-\n",
      "ponents: (1) Storage Module; (2) Preparation Mod-\n",
      "ule; and (3) Data and Knowledge Extraction Module.\n",
      "The Storage Module houses a centralized re-\n",
      "lational database, constructed from various data\n",
      "sources.\n",
      "The database is described by a concep-\n",
      "tual schema, treated in what follows as a relational\n",
      "schema, again for simplicity.\n",
      "The Storage Module also holds the data indices\n",
      "required to support the keyword search service. The\n",
      "indexing process is enriched to create a keyword dic-\n",
      "tionary containing:\n",
      "• for each table T, an entry of the form (T,TS),\n",
      "where TS is a list of terms users adopt to refer to\n",
      "table T.\n",
      "• for each column A of a table T, an entry of the\n",
      "form (A,T,AS), where AS is a list of terms that\n",
      "users adopt to refer to column A in the context of\n",
      "table T.\n",
      "• for each indexed value v, an entry of the form\n",
      "(v,T,A), where T[A] is the table/column where v\n",
      "occurs.\n",
      "The Preparation Module has tools for creating the\n",
      "conceptual schema and for constructing and updat-\n",
      "ing the centralized database through a pipeline typ-\n",
      "ical of a data integration process.\n",
      "The conceptual\n",
      "schema is defined by de-normalizing the relational\n",
      "schemas of the underlying databases and indicating\n",
      "which columns will have their values indexed.\n",
      "The Data and Knowledge Extraction Module\n",
      "has two main sub-modules, Query Compilation and\n",
      "Query Processing.\n",
      "Given a keyword query, represented by a list of\n",
      "keywords, the Query Compilation Module has three\n",
      "major steps:\n",
      "1. (Matching Discovery) Match each keyword in the\n",
      "keyword query with table and column names or\n",
      "data values in the keyword dictionary.\n",
      "2. (Matching Optimization) Select the most relevant\n",
      "matches.\n",
      "3. (Conceptual Query Compilation) Compile a con-\n",
      "ceptual query over the conceptual schema from\n",
      "the most relevant matches.\n",
      "The Query Processing Module, in turn, has two\n",
      "major steps:\n",
      "1. (Query Compilation) Compile the conceptual\n",
      "query into an SQL query.\n",
      "2. (Query Execution) Submit the SQL query for exe-\n",
      "cution, collect the results, and display them to the\n",
      "user.\n",
      "Let R be the referential dependencies diagram of\n",
      "the database schema in question, where the nodes of\n",
      "R are the tables and there is an edge between nodes\n",
      "t and u iff there is a foreign key from t to u or vice-\n",
      "versa. Given a set of keywords K, let TK be a set of\n",
      "table schemes whose instances match the largest set\n",
      "of keywords in K. The conceptual query compilation\n",
      "step first constructs a Steiner tree SK of R whose end\n",
      "nodes are the set TK. This is the central point since it\n",
      "guarantees that the final SQL query will not return un-\n",
      "connected data, as explored in detail in (Garc´ıa et al.,\n",
      "2017). If R is connected, then it is always possible to\n",
      "construct one such Steiner tree; overwise, one would\n",
      "have to find a Steiner forest to cover all tables in TK.\n",
      "Using the Steiner tree, the Query Compilation step\n",
      "compiles the keyword query into an SQL query that\n",
      "includes restriction clauses representing the keyword\n",
      "matches and join clauses connecting the restriction\n",
      "clauses. Without such join clauses, an answer would\n",
      "be a disconnected set of tuples, which hardly makes\n",
      "sense.\n",
      "The generation of the join clauses uses the\n",
      "Steiner tree edges.\n",
      "Lastly, DANKE’s internal API was expanded to\n",
      "support the text-to-SQL strategy described in Section\n",
      "4. Briefly, it now offers the following services:\n",
      "• Keyword Match Service: receives a set K of key-\n",
      "words and returns the set KM of pairs (k,dk) such\n",
      "that k ∈K and dk is the dictionary entry that\n",
      "best matches k, using the matching optimization\n",
      "heuristic mentioned above. The dictionary entry\n",
      "dk will be called the data associated with k.\n",
      "• View Synthesis Service: receives a set S′ of tables\n",
      "and returns a view V that best joins all tables in S′,\n",
      "using the Steiner tree optimization heuristic men-\n",
      "tioned above.\n",
      "4\n",
      "A STRATEGY FOR THE\n",
      "TEXT-TO-SQL TASK\n",
      "4.1\n",
      "Outline of the Proposed Strategy\n",
      "Briefly, the proposed strategy comprises two modules,\n",
      "schema linking and SQL query compilation, as typical\n",
      "of text-to-SQL prompt strategies. Figure 1 summa-\n",
      "rizes the proposed strategy, leaving the details to the\n",
      "next sections.\n",
      "The two modules run under LangChain.\n",
      "They\n",
      "use a dynamic few-shot examples strategy that re-\n",
      "trieves a set of samples from a synthetic dataset D,\n",
      "Figure 1: Proposed strategy.\n",
      "indexed with the help of the FAISS similarity search\n",
      "library10. The key point is the use of services pro-\n",
      "vided by DANKE to enhance schema linking and sim-\n",
      "plify SQL compilation, as explained in the following\n",
      "sections. In particular, DANKE will generate a sin-\n",
      "gle SQL view containing all data and encapsulating\n",
      "all joins necessary to answer the input NL question.\n",
      "The\n",
      "current\n",
      "implementation\n",
      "runs\n",
      "in-house:\n",
      "LangChain, FAISS, DANKE, and Oracle. The exper-\n",
      "iments used the OpenAI GPT-4 and its variations, as\n",
      "detailed in Section 5.\n",
      "4.2\n",
      "Synthetic Dataset Construction\n",
      "Let DB be a relational database with schema S. A\n",
      "synthetic dataset D for DB contains pairs (QN,QSQL),\n",
      "where QN is an NL question and QSQL is its SQL\n",
      "translation. Such pairs should provide examples that\n",
      "help the LLM understand how the database schema is\n",
      "structured, how the user’s terms map to terms of the\n",
      "database schema, and how NL language constructions\n",
      "map to data values.\n",
      "The synthetic dataset construction process repeat-\n",
      "edly calls Algorithm 1 to generate as many pairs\n",
      "(QN,QSQL) as desired. The parameter n is set in each\n",
      "call to determine how many tables the SQL query\n",
      "should involve.\n",
      "Step 1 (on Line 2) selects a set T of n tables from\n",
      "the database schema S. The selection process employs\n",
      "a weighted random distribution, which reflects the\n",
      "likelihood of each table being chosen by an average\n",
      "user. Note that users may choose some tables more of-\n",
      "ten than others, which justifies employing a weighted\n",
      "random distribution, obtained from the users’ access\n",
      "log.\n",
      "Step 2 (on Line 3) selects column pairs for each\n",
      "10https://ai.meta.com/tools/faiss/\n",
      "Algorithm 1: Generating examples for the synthetic\n",
      "dataset.\n",
      "Data: the number n of tables to select, the\n",
      "database DB, the database schema S,\n",
      "and the database documentation\n",
      "DBdoc, if available.\n",
      "Result: a pair (QN,QSQL) where QN is an NL\n",
      "question and QSQL is the\n",
      "corresponding SQL query.\n",
      "1 Function CreateExample(n,DB,S,DBdoc):\n",
      "2\n",
      "T ←SelectTables(n,S);\n",
      "3\n",
      "C ←SelectColumns(T,S);\n",
      "4\n",
      "L ←CreateDDL(T,C);\n",
      "5\n",
      "QN′ ←CreateQuestion(L);\n",
      "6\n",
      "QSQL ←GenerateSQL(QN′,L);\n",
      "7\n",
      "QN ←ImproveQuestion(QN′,S,DBdoc);\n",
      "8\n",
      "return (QN,QSQL);\n",
      "table chosen in Step 1. The first column selected is\n",
      "always the primary key of the table, and the second\n",
      "column is chosen based on the weighted random dis-\n",
      "tribution of each column in the database schema S.\n",
      "Step 3 (on Line 4) creates a simplified Data Def-\n",
      "inition Language (DDL) statement L, encompassing\n",
      "only the columns and tables involved. Column and\n",
      "table names are renamed to their respective names in\n",
      "the conceptual schema views (see Section 5.1.3).\n",
      "Step 4 (on Line 5) creates an NL question QN′\n",
      "by prompting GPT-4 with the simplified DDL state-\n",
      "ment L and sample values of each column from the\n",
      "database DB. In addition, the prompt includes the\n",
      "type of restriction to be incorporated into the NL\n",
      "question, which depends on the data type of each\n",
      "column. For example, numeric-type columns can be\n",
      "used to create queries with aggregations. Finally, the\n",
      "prompt includes instructions that indicate that QN′\n",
      "must be generated in the database vocabulary; that is,\n",
      "the table and column names must be kept to facilitate\n",
      "the generation of the SQL corresponding to the NL\n",
      "question.\n",
      "Step 5 (on Line 6) calls GPT-4 to translate QN′\n",
      "into an SQL query that responds to the NL question\n",
      "by providing QN′ and L. This process is facilitated by\n",
      "the fact that the SQL query should use the database\n",
      "schema vocabulary; that is, the prompt provides clues\n",
      "about which tables, columns, and values are involved.\n",
      "The key point is to explore the column type to de-\n",
      "cide which SQL construct must be used to express\n",
      "a restriction for the column. For example, given a\n",
      "string B, if column INSTALLATION NAME were of type\n",
      "STRING and not a key, the prompt would guide GPT-4\n",
      "to create a restriction of the form\n",
      "INSTALLATION NAME LIKE ‘%B%’\n",
      "However, if column INSTALLATION NAME were a key,\n",
      "then the prompt would guide GPT-4 to create a re-\n",
      "striction of the form\n",
      "INSTALLATION NAME = ‘B’\n",
      "Finally, Step 6 (on Line 7) calls GPT-4 to trans-\n",
      "late QN′ into an improved NL question QN, using\n",
      "the database documentation DBdoc, which includes\n",
      "the description of each column and table, along with\n",
      "synonyms. During this step, the LLM is instructed\n",
      "to rephrase the NL question by translating from the\n",
      "database schema vocabulary to the user’s vocabulary,\n",
      "preserving the original NL question intent.\n",
      "4.3\n",
      "Schema Linking\n",
      "Let DB be a relational database with schema S and D\n",
      "be the synthetic dataset created for DB. Let QN be an\n",
      "NL question over S.\n",
      "The schema linking module primarily finds a min-\n",
      "imal set S′ ⊂S such that S′ has all tables in S required\n",
      "to answer QN. It has the following major components\n",
      "(see Figure 2):\n",
      "Keyword Extraction and Matching\n",
      "1. Receives as input an NL question QN.\n",
      "2. Calls the LLM to extract a set K of keywords\n",
      "from QN.\n",
      "3. Calls the DANKE Keyword Matching service\n",
      "to match K with the dictionary, creating a final\n",
      "set KM of keywords and associated data.\n",
      "4. Returns KM.\n",
      "Dynamic Few-shot Examples Retrieval (DFE)\n",
      "1. Receives as input an NL question QN.\n",
      "2. Retrieves from the synthetic dataset D a set of k\n",
      "examples whose NL questions are most similar\n",
      "to QN, generating\n",
      "L = [(Q1,SQL1),...,(Qk,SQLk)]\n",
      "3. Creates a list T of pairs by retaining only the\n",
      "table names in the FROM clauses, that is,\n",
      "T = [(Q1,F1),...,(Qk,Fk)]\n",
      "where Fi is the set of tables in the FROM clause\n",
      "of SQLi.\n",
      "4. Returns T.\n",
      "Schema Linking\n",
      "1. Receives as input an NL question QN, a set KM\n",
      "of keywords and associated data, and a list T as\n",
      "above.\n",
      "2. Retrieves the set of tables in S and their\n",
      "columns.\n",
      "3. Calls the LLM to create S′ prompted by QN,\n",
      "KM, S, and T.\n",
      "4. Returns S′ and KM.\n",
      "Figure 2: Schema linking module.\n",
      "4.4\n",
      "SQL Query Compilation\n",
      "The SQL query compilation module receives as input\n",
      "the NL question QN, the set of tables S′, and the set\n",
      "KM of keywords and associated data, and returns an\n",
      "SQL query QSQL. It has the following major compo-\n",
      "nents (see Figure 3):\n",
      "View Synthesis\n",
      "1. Receives as input a set of tables S′.\n",
      "2. Calls the DANKE View Synthesis service to\n",
      "synthesize a view V that joins the tables in S′.\n",
      "3. Returns V.\n",
      "Question Decomposition\n",
      "1. Receives as input an NL question QN.\n",
      "2. Decomposes QN into sub-questions Q1,...,Qm.\n",
      "3. Returns Q1,...,Qm.\n",
      "Dynamic Few-shot Examples Retrieval (DFE)\n",
      "1. Receives as input a list of NL questions\n",
      "Q1,...,Qm.\n",
      "2. Let p = ⌈k/m⌉. For each i ∈[1,m], retrieves\n",
      "from the synthetic dataset D a set of p examples\n",
      "whose NL questions are most similar to Qi and\n",
      "whose SQL queries are over S′, generating a list\n",
      "Li = [(Qi1,SQLi1),...,(Qip,SQLip)]\n",
      "in decreasing order of similarity of Qij to Qi.\n",
      "3. Creates the final list L, with k elements, by in-\n",
      "tercalating the lists Li and retaining the top-k\n",
      "pairs.\n",
      "4. Returns L.\n",
      "SQL Compilation\n",
      "1. Receives as input a view V, a set KM of key-\n",
      "words and associated data, an NL question QN,\n",
      "and a list L as above.\n",
      "2. In each SQL query SQLij in L, replaces all ta-\n",
      "bles in the FROM clauses by V, creating a new\n",
      "list L′.\n",
      "3. Retrieves from DB a set M of row samples of\n",
      "V.\n",
      "4. Calls the LLM to compile QN into an SQL\n",
      "query QSQL over V, when prompted with QN,\n",
      "V, KM, M and L′.\n",
      "5. Returns QSQL.\n",
      "Figure 3: SQL query compilation module.\n",
      "4.5\n",
      "Limitations and Examples\n",
      "If the proposed text-to-SQL strategy can compile an\n",
      "NL question QN into an SQL query QSQL, then QSQL\n",
      "is such that:\n",
      "• QSQL is defined over a single table V.\n",
      "• V is a view defined by an SQL query over a sin-\n",
      "gle table or a block of equijoin clauses, with no\n",
      "WHERE clause and no optional clauses (GROUP\n",
      "BY, HAVING, ORDER BY, and LIMIT clauses).\n",
      "These conditions reflect the way the text-to-SQL\n",
      "strategy is structured. Indeed, first, observe that, in\n",
      "the SQL Query Compilation module, the View Syn-\n",
      "thesis step calls DANKE’s View Synthesis Service to\n",
      "create a view V, defined by a set of equijoin clauses\n",
      "over the set of tables S′ passed by the schema linking\n",
      "module. This step improves the (manual) approach\n",
      "proposed in (Nascimento et al., 2024b).\n",
      "Then, the SQL Compilation step prompts the LLM\n",
      "with view V to generate the SQL query. View V then\n",
      "facilitates the translation of an NL question into an\n",
      "SQL query since the LLM no longer needs to discover\n",
      "which joins to include in the SQL query.\n",
      "The predicted SQL queries and the views in Tables\n",
      "5 and 6 at the end of the paper provide examples of\n",
      "such NL questions, SQL queries, and views, two of\n",
      "which are discussed in more detail in what follows.\n",
      "As a very simple example,\n",
      "consider Ques-\n",
      "tion 24 in Table 5, which requires joining tables\n",
      "Recommendation and Installation, as its ground-\n",
      "truth SQL query indicates. The schema linking mod-\n",
      "ule can compute that Question 24 requires these two\n",
      "tables. Then, the View Synthesis step calls DANKE,\n",
      "which receives the relational schema (see Table 4) and\n",
      "these two tables, finds the required join, and synthe-\n",
      "sizes the following view (some details of the view def-\n",
      "inition are omitted here for brevity):\n",
      "CREATE VIEW\n",
      "Recommendation_Installation AS\n",
      "SELECT r.id AS\n",
      "Recommendation_id ,\n",
      "r.situation AS\n",
      "Recommendation_situation ,\n",
      "...\n",
      "FROM Recommendation r\n",
      "JOIN Installation p\n",
      "ON r.installation_name =\n",
      "p.name\n",
      "As a result, the SQL compilation step generates an\n",
      "SQL query without explicitly including this join (see\n",
      "the predicted SQL query for Question 24 in Table 5).\n",
      "The SQL compilation step prompts this view to\n",
      "the LLM as if it were a table in DDL format:\n",
      "CREATE TABLE\n",
      "Recommendation_Installation\n",
      "(Recommendation_id ,\n",
      "Recommendation_situation ,...)\n",
      "However, this very simple example does not fully\n",
      "illustrate the power of using DANKE to join any num-\n",
      "ber of tables. A slightly more complex example goes\n",
      "as follows.\n",
      "Consider Question 93 in Table 6, which re-\n",
      "quires\n",
      "joining\n",
      "tables\n",
      "Maintenance request,\n",
      "Maintenance recommendation,\n",
      "and\n",
      "Maintenance order,\n",
      "as\n",
      "its\n",
      "ground-truth\n",
      "SQL\n",
      "query indicates. Again, the schema linking module\n",
      "can compute that Question 93 requires these three\n",
      "tables. Then, the View Synthesis step calls DANKE,\n",
      "which receives the relational schema and these three\n",
      "tables, finds the required two joins, and synthesizes\n",
      "the following view (again, some details of the view\n",
      "definition are omitted here for brevity):\n",
      "CREATE VIEW\n",
      "Request_Recommendation_Order AS\n",
      "SELECT m.id AS Request_id ,\n",
      "r.id AS Recommendation_id ,\n",
      "o.id AS Order_id ,\n",
      "...\n",
      "FROM Maintenance_request m\n",
      "JOIN Maintenance_recommendation r\n",
      "ON m.id = r.note_id\n",
      "JOIN Maintenance_order o\n",
      "ON r.order_id = o.id\n",
      "As a result, the SQL compilation step generates an\n",
      "SQL query without explicitly including these joins\n",
      "(see the predicted SQL query for Question 93 in Table\n",
      "6).\n",
      "The SQL compilation step prompts this view to\n",
      "the LLM as if it were a table in DDL format:\n",
      "CREATE TABLE\n",
      "Request_Recommendation_Order\n",
      "(Request_id ,\n",
      "Recommendation_id ,\n",
      "Order_id ,...)\n",
      "5\n",
      "EXPERIMENTS\n",
      "5.1\n",
      "A Benchmark Dataset\n",
      "This section describes a benchmark to help inves-\n",
      "tigate the real-world text-to-SQL task. The bench-\n",
      "mark consists of a relational database, a set of 100\n",
      "test NL questions and their SQL ground-truth transla-\n",
      "tions, and a set of partially extended views.\n",
      "5.1.1\n",
      "The Relational Database\n",
      "The selected database is a real-world relational\n",
      "database (in Oracle) that stores data related to the in-\n",
      "tegrity management of an energy company’s indus-\n",
      "trial assets.\n",
      "The relational schema of the adopted\n",
      "database contains 27 relational tables with, in to-\n",
      "tal, 585 columns and 30 foreign keys (some multi-\n",
      "column), where the largest table has 81 columns.\n",
      "Figure 4 shows the referential dependencies dia-\n",
      "gram of a much-simplified and anonymized version\n",
      "of the relational schema of the real-world database,\n",
      "where an arrow represents a foreign key and points to\n",
      "the referenced table, as usual. Note that the diagram\n",
      "is a connected graph, which implies that, given any\n",
      "set of tables T of the relational schema, it is always\n",
      "possible to create a Steiner tree of the diagram that\n",
      "covers all tables in T. This implies that Step 1 of the\n",
      "SQL Query compilation process will always succeed\n",
      "in creating the required view.\n",
      "5.1.2\n",
      "The Set of Test Questions and their\n",
      "Ground-Truth SQL Translations\n",
      "The benchmark contains a set of 100 NL questions\n",
      "that consider the terms and questions experts use\n",
      "when requesting information related to the mainte-\n",
      "nance and integrity processes. The ground-truth SQL\n",
      "queries were manually defined over the conceptual\n",
      "schema views so that the execution of a ground-truth\n",
      "SQL query returns the expected answer to the corre-\n",
      "sponding NL question.\n",
      "An NL question is classified into simple, medium,\n",
      "and complex, based on the complexity of its cor-\n",
      "responding ground-truth SQL query, as in the Spi-\n",
      "der benchmark (extra-hard questions were not con-\n",
      "sidered). The set L contains 33 simple, 33 medium,\n",
      "and 34 complex NL questions, with the basic statistics\n",
      "shown in Table 1. Tables 4, 5, and 6 at the end of the\n",
      "paper show three examples of each of these classes.\n",
      "Table 1: Basic statistics of the sets of queries (Nascimento\n",
      "et al., 2024a).\n",
      "5.1.3\n",
      "The Set of Partially Extended Views\n",
      "The benchmark also includes a set of partially ex-\n",
      "tended views (Nascimento et al., 2024b) that rename\n",
      "table and column names of the relational schema to\n",
      "end users’ terms. Such views also have new columns\n",
      "that pre-define joins that follow foreign keys and im-\n",
      "port selected columns from the referenced tables to\n",
      "facilitate SQL query compilation.\n",
      "They are maintained in the benchmark since they\n",
      "were used in the earlier experiments reported in Lines\n",
      "1 to 3 of Table 3.\n",
      "5.2\n",
      "Evaluation Procedure\n",
      "The experiments used an automated procedure to\n",
      "compare the predicted and the ground-truth SQL\n",
      "queries, entirely based on column and table values,\n",
      "and not just column and table names. Therefore, a\n",
      "text-to-SQL tool may generate SQL queries over the\n",
      "relational schema or any set of views, and the result-\n",
      "ing SQL queries may be compared with the ground-\n",
      "truth SQL queries based on the results returned. The\n",
      "results of the automated procedure were manually\n",
      "checked to eliminate false positives and false nega-\n",
      "Figure 4: The referential dependencies diagram of a simplified and anonymized version of the industrial database schema.\n",
      "tives. The reader is referred to (Nascimento et al.,\n",
      "2024a) for the details.\n",
      "5.3\n",
      "Experiments with Schema Linking\n",
      "5.3.1\n",
      "Experimental Setup\n",
      "The first set of experiments evaluated several alterna-\n",
      "tives for performing the schema linking task.\n",
      "The experiments adopted the benchmark de-\n",
      "scribed in Section 5.1.\n",
      "For each NL question, the\n",
      "ground-truth minimum sets of tables necessary to an-\n",
      "swer the NL question is the set of tables in the FROM\n",
      "clause of the ground-truth SQL query. The experi-\n",
      "ments used GPT-3.5 Turbo and GPT-4, but only the\n",
      "results obtained with GPT-4 were noteworthy.\n",
      "Table 2 presents the results of the experiments for\n",
      "the following alternatives:\n",
      "1. (LLM): A strategy that prompts an LLM with QN\n",
      "and S to find the set of tables S′.\n",
      "2. (DANKE): A strategy that, first, uses DANKE to\n",
      "extract a set of keywords K from QN, and then\n",
      "extracts the set of tables S′ from the information\n",
      "associated with K in DANKE’s dictionary.\n",
      "3. (LLM+DFE): A strategy that, first, finds a set of\n",
      "examples T from D using QN, and then prompts\n",
      "an LLM with QN, S, and T to find the set of tables\n",
      "S′.\n",
      "4. (LLM+DANKE): A strategy that, first, uses an\n",
      "LLM to extract a set K of keywords from QN, and\n",
      "then extracts the set of tables S′ from the informa-\n",
      "tion associated with K in DANKE’s dictionary.\n",
      "5. (LLM+DANKE+DFE): A strategy that, first, uses\n",
      "an LLM to extract a set K of keywords from QN,\n",
      "retrieves the information associated with K from\n",
      "DANKE’s dictionary, creating a set KM, finds a set\n",
      "of examples T from D using QN, and then prompts\n",
      "an LLM with QN, S, KM, and T to find the set of\n",
      "tables S′.\n",
      "6. (Complete): The entire Schema Linking process.\n",
      "5.3.2\n",
      "Results\n",
      "Table 2 presents the precision, recall, and F1-score for\n",
      "the experiments using the Schema Linking process.\n",
      "Briefly, the results show that:\n",
      "1. (LLM): Alternative 1 obtained an F1-score of\n",
      "0.851. It had a performance poorer than Alter-\n",
      "native 2, which used just DANKE.\n",
      "2. (DANKE): Alternative 2 obtained an F1-score of\n",
      "0.900. Note that DANKE achieved a better re-\n",
      "sult than Alternatives 1 and 3 (which do not use\n",
      "DANKE), although DANKE does no syntactic or\n",
      "semantic processing of the user question QN, and\n",
      "may incorrectly match terms in QN to terms in the\n",
      "database schema or to data values.\n",
      "3. (LLM+DFE): Alternative 3 obtained an F1-score\n",
      "of 0.868. The use of DFE improved the results\n",
      "achieved by Alternative 1, but the results were still\n",
      "lower than those of Alternative 2.\n",
      "4. (LLM+DANKE): Alternative 4 increased the F1-\n",
      "score to 0.930.\n",
      "Enriching the prompt with the\n",
      "keywords extracted by DANKE from QN yielded\n",
      "consistent improvements in both precision and re-\n",
      "call. This is due to DANKE’s ability to find refer-\n",
      "ences to column values, associating them with the\n",
      "table/column where the value occurs. This fea-\n",
      "ture allowed DANKE to find implicit references\n",
      "that were previously impossible for the LLM to\n",
      "discover since it had no knowledge about the\n",
      "database instances.\n",
      "5. (LLM+DANKE+DFE): Alternative 5 increased\n",
      "the F1-score to 0.950.\n",
      "6. (Complete – GPT-4): The complete Schema Link-\n",
      "ing process achieved an F1-Score of 0.996, the\n",
      "best result. Using the LLM to extract keywords\n",
      "from QN improved the results of DANKE. Al-\n",
      "though DANKE may still return incorrect terms,\n",
      "the LLM corrects them.\n",
      "7. (Complete – GPT-4o): Using GPT-4o resulted in\n",
      "a slight decrease in the F1-score to 0.995.\n",
      "Table 2: Results for the schema linking alternatives (all with\n",
      "GPT-4, except the last line).\n",
      "#\n",
      "Method\n",
      "Precision\n",
      "Recall\n",
      "F1-score\n",
      "1\n",
      "LLM\n",
      "0.864\n",
      "0.886\n",
      "0.851\n",
      "2\n",
      "DANKE\n",
      "0.860\n",
      "0.983\n",
      "0.900\n",
      "3\n",
      "LLM+DFE\n",
      "0.940\n",
      "0.843\n",
      "0.868\n",
      "4\n",
      "LLM+DANKE\n",
      "0.930\n",
      "0.930\n",
      "0.930\n",
      "5\n",
      "LLM+DFE+DANKE\n",
      "0.993\n",
      "0.983\n",
      "0.950\n",
      "6\n",
      "Complete – GPT-4\n",
      "0.993\n",
      "1.000\n",
      "0.996\n",
      "7\n",
      "Complete – GPT-4o\n",
      "1.000\n",
      "0.995\n",
      "0.995\n",
      "In general, these results show that DANKE, to-\n",
      "gether with the LLM, performed effectively in the\n",
      "Schema Linking process for NL questions.\n",
      "Con-\n",
      "sidering that the complete Schema Linking process\n",
      "achieved a recall of 1.0, it returned all tables required\n",
      "to answer each NL question. Thus, the Schema Link-\n",
      "ing process does not impact the SQL Query Compila-\n",
      "tion step, although the extra tables may create distrac-\n",
      "tions for the LLM (see Section 5.4).\n",
      "5.4\n",
      "Experiments with SQL Query\n",
      "Compilation\n",
      "5.4.1\n",
      "Experimental Setup\n",
      "The experiments were based on LangChain SQL-\n",
      "QueryChain11, which automatically extracts metadata\n",
      "from the database, creates a prompt with the metadata\n",
      "and passes it to the LLM. This chain greatly simplifies\n",
      "creating prompts to access databases through views\n",
      "since it passes a view specification as if it were a table\n",
      "specification.\n",
      "The experiments executed the 100 questions intro-\n",
      "duced in Section 5.1.2 in nine alternatives:\n",
      "1. (Relational Schema): SQLQueryChain executed\n",
      "over the relational schema of the benchmark\n",
      "database.\n",
      "2. (Partially Extended Views): SQLQueryChain ex-\n",
      "ecuted over the partially extended views of the\n",
      "benchmark database.\n",
      "11https://docs.langchain.com\n",
      "3. (Partially Extended Views and DFE): SQL-\n",
      "QueryChain executed over the partially extended\n",
      "views using only the DFE technique.\n",
      "4. (Partially Extended Views, DFE, and Question\n",
      "Decomposition): SQLQueryChain executed over\n",
      "the partially extended views, using Question De-\n",
      "composition and the DFE technique.\n",
      "5. (The Proposed Text-to-SQL Strategy – GPT-4):\n",
      "The proposed Text-to-SQL Strategy, using GPT-\n",
      "4-32K.\n",
      "6. (The Proposed Text-to-SQL Strategy – GPT-4o):\n",
      "The proposed Text-to-SQL Strategy, using GPT-\n",
      "4o.\n",
      "7. (The Proposed Text-to-SQL Strategy – LLaMA\n",
      "3.1-405B-Instruct):\n",
      "The proposed Text-to-SQL\n",
      "Strategy, using LLaMA 3.1-405B-Instruct.\n",
      "8. (The Proposed Text-to-SQL Strategy – Mistral\n",
      "Large): The proposed Text-to-SQL Strategy, us-\n",
      "ing Mistral Large.\n",
      "9. (The Proposed Text-to-SQL Strategy – Claude\n",
      "3.5-Sonnet): The proposed Text-to-SQL Strategy,\n",
      "using Claude 3.5-Sonnet.\n",
      "Alternatives 1–6 ran on the OpenAI platform, and\n",
      "Alternatives 7–9 on the AWS Bedrock platform.\n",
      "Also, recall that:\n",
      "• GPT-4-32K has a context window of 32K tokens.\n",
      "• GPT-4o has a context window of 128K tokens.\n",
      "• Llama 3.1-405B Instruct has 405B parameters and\n",
      "a context window of 128K tokens.\n",
      "• Mistral Large has 123B parameters and a context\n",
      "window of 32K tokens.\n",
      "• Claude 3.5 Sonnet has 175B parameters and a\n",
      "context window of 200K tokens.\n",
      "5.4.2\n",
      "Results\n",
      "Table 3 summarizes the results for the various alter-\n",
      "natives. Columns under “#Correct Predicted Ques-\n",
      "tions” show the number of NL questions per type cor-\n",
      "rectly translated to SQL (recall that there are 33 sim-\n",
      "ple, 33 medium, and 34 complex NL questions, with a\n",
      "total of 100); columns under “Accuracy” indicate the\n",
      "accuracy results per NL question type and the overall\n",
      "accuracy; the last column shows the total elapsed time\n",
      "to run all 100 NL questions.\n",
      "The results for Alternatives 1, 2, and 3 were\n",
      "reported in (Nascimento et al., 2024a; Nascimento\n",
      "et al., 2024b; Coelho et al., 2024), respectively. They\n",
      "are repeated in Table 3 for comparison with the results\n",
      "of this paper.\n",
      "Table 3: Summary of the results.\n",
      "The results for Alternative 4 show that Question\n",
      "Decomposition produced an improvement in total ac-\n",
      "curacy from 0.79 to 0.84. This reflects the diversity\n",
      "of examples passed to the LLM when they are re-\n",
      "trieved for each sub-question, as already pointed out\n",
      "in (Oliveira et al., 2025).\n",
      "The results for Alternative 5 show that the key\n",
      "contribution of this paper, the text-to-SQL strategy\n",
      "described in Section 4, indeed leads to a significant\n",
      "improvement in the total accuracy for the case study\n",
      "database, as well as the accuracies for the medium and\n",
      "complex NL questions.\n",
      "The results for Alternative 6 indicate a slight de-\n",
      "crease in the total accuracy to 0.90 when GPT-4o is\n",
      "adopted, possibly due to the non-deterministic behav-\n",
      "ior of the models. However, while GPT-4-32K took\n",
      "17 minutes to run all 100 questions, GPT-4o took only\n",
      "7 minutes.\n",
      "The results for Alternatives 7–9 show a decrease\n",
      "in the total accuracy to 0.81%, 0.77%, and 0.74%,\n",
      "respectively, with a much higher total elapsed time\n",
      "when compared with GPT-4o, but comparable to that\n",
      "of GPT-4-32K.\n",
      "5.4.3\n",
      "Discussion\n",
      "In all alternatives that did not resort to DANKE, the\n",
      "LLM had all the Schema Linking burden, and had to\n",
      "synthesize all the joins required to process the NL\n",
      "question correctly. By contrast, the strategy of Sec-\n",
      "tion 4, by using DANKE, alleviated these burdens.\n",
      "DANKE also helped the LLM with ambiguous\n",
      "questions both during the Schema Linking and the\n",
      "SQL Query Compilation processes.\n",
      "In a few cases, Schema Linking returned more ta-\n",
      "bles than required. But, in most of these cases, the\n",
      "SQL Query Compilation process was not jeopardized;\n",
      "in only one case, the extra tables and consequently\n",
      "the extra columns in the view led the LLM to con-\n",
      "fuse the choice of columns, and synthesize an incor-\n",
      "rect WHERE clause.\n",
      "The results in Table 3 show that the proposed strat-\n",
      "egy (Line 5) correctly processed four more medium\n",
      "NL questions and six more NL complex questions\n",
      "than the previous best strategy (Line 4). However,\n",
      "these results hide the fact that the proposed strategy\n",
      "processed four complex NL questions that none of the\n",
      "strategies previously tested on the same database and\n",
      "set of questions have correctly handled, including C3\n",
      "and DIN. Table 6 shows three such NL questions. For\n",
      "example, in Question 29, the previous strategies did\n",
      "not correctly synthesize the required join, whereas the\n",
      "view created in Step 1 of the SQL Query compilation\n",
      "process (see Section 4.4) indeed includes such join,\n",
      "making it easier for the LLM to compile the required\n",
      "SQL query. In Question 93, all previous strategies\n",
      "failed to remap the installation name “E176” in the\n",
      "user question to the installation name “E-176” stored\n",
      "in the database; the proposed strategy used DANKE’s\n",
      "matches to correct this problem.\n",
      "Similar observations are valid for the medium NL\n",
      "questions. For example, the previous strategies did\n",
      "not correctly process Question 24 in Table 5, whereas\n",
      "the proposed strategy did, using DANKE’s matches.\n",
      "An analysis of the NL questions compiled into\n",
      "incorrect SQL queries uncovered that the proposed\n",
      "strategy failed for two basic reasons: (1) the seman-\n",
      "tics of a term of the NL question was mapped into an\n",
      "incorrect SQL filter (i.e., due to a semantic mismatch);\n",
      "and (2) a term of the NL question was associated with\n",
      "an incorrect column name.\n",
      "As for the other models – Llama 3.1-405B In-\n",
      "struct, Mistral Large, and Claude 3.5 Sonnet – the\n",
      "most common source of error was the use of the CON-\n",
      "TAINS function, which requires the target column to\n",
      "be indexed, but this was not always the case; the cor-\n",
      "rect filter would have to use LIKE.\n",
      "6\n",
      "CONCLUSIONS\n",
      "This paper proposed a strategy to compile NL ques-\n",
      "tions into SQL queries, especially questions that re-\n",
      "quire complex filters and joins, that leverages the\n",
      "services provided by DANKE, a database keyword\n",
      "search platform.\n",
      "The paper detailed how the schema-linking pro-\n",
      "cess can be improved with the help of the keyword\n",
      "extraction service that DANKE provides.\n",
      "Then, it\n",
      "showed how DANKE can be used to synthesize a\n",
      "view that captures the joins required to process an in-\n",
      "put NL question and thereby simplify the SQL query\n",
      "compilation step.\n",
      "Both the schema-linking and the SQL query com-\n",
      "pilation processes use a dynamic few-shot technique,\n",
      "based on a synthetic dataset constructed from the\n",
      "database. Section 4.2 described a technique for con-\n",
      "structing the synthetic dataset that improves the tech-\n",
      "nique introduced in (Coelho et al., 2024).\n",
      "The paper included experiments with a real-world\n",
      "relational database to assess the performance of the\n",
      "proposed strategy. The results in Section 5.3 showed\n",
      "that the precision and recall of the schema-linking\n",
      "process indeed improved with the help of the keyword\n",
      "extraction service that DANKE provides. The discus-\n",
      "sion in Section 5.4 suggested that creating a view with\n",
      "the help of DANKE also helped with the SQL query\n",
      "compilation process. In conjunction, these results in-\n",
      "dicated that the proposed strategy achieved a total ac-\n",
      "curacy in excess of 90% over a benchmark built upon\n",
      "a relational database with a challenging schema and\n",
      "a set of 100 questions carefully defined to reflect the\n",
      "questions users submit and to cover a wide range of\n",
      "SQL constructs. The total accuracy was much higher\n",
      "than that achieved by SQLCoder, LangChain SQL-\n",
      "QueryChain, C3, and DIN+SQL on the same bench-\n",
      "mark, as reported in (Nascimento et al., 2024a).\n",
      "As future work, the proposed strategy should be\n",
      "tested and compared against other strategies using\n",
      "additional databases and test questions.\n",
      "This ef-\n",
      "fort depends, however, on working with real-world\n",
      "databases that are available, populated, and with good\n",
      "documentation. As a first step, the strategy has al-\n",
      "ready been applied to other databases that are in pro-\n",
      "duction and to the openly available Mondial database,\n",
      "with positive results.\n",
      "A second demand is to address the problem that\n",
      "Natural Language questions are intrinsically ambigu-\n",
      "ous. The use of DANKE’s matching process helps,\n",
      "but it should be complemented with a different ap-\n",
      "proach, perhaps incorporating the user in a disam-\n",
      "biguation loop.\n",
      "Finally, it should also be stressed that the proposed\n",
      "strategy and the synthetic dataset construction process\n",
      "are generic, but costly to set up. They should be con-\n",
      "sidered when it is worth investing in an NL interface\n",
      "for a serious database where accuracy is at stake.\n",
      "ACKNOWLEDGEMENTS\n",
      "This work was partly funded by FAPERJ under\n",
      "grant E-26/204.322/2024;\n",
      "by CNPq under grant\n",
      "302303/2017-0; and by Petrobras, under research\n",
      "agreement 2022/00032-9 between CENPES and\n",
      "PUC-Rio.\n",
      "REFERENCES\n",
      "Affolter, K., Stockinger, K., and Bernstein, A. (2019). A\n",
      "comparative survey of recent natural language inter-\n",
      "faces for databases. The VLDB Journal, 28:793–819.\n",
      "Coelho, G., Nascimento, E. S., Izquierdo, Y., Garc´ıa, G.,\n",
      "Feij´o, L., Lemos, M., Garcia, R., de Oliveira, A., Pin-\n",
      "heiro, J., and Casanova, M. (2024).\n",
      "Improving the\n",
      "accuracy of text-to-sql tools based on large language\n",
      "models for real-world relational databases. In Strauss,\n",
      "C., Amagasa, T., Manco, G., Kotsis, G., Tjoa, A.,\n",
      "and Khalil, I., editors, Database and Expert Systems\n",
      "Applications, pages 93–107, Cham. Springer Nature\n",
      "Switzerland.\n",
      "Dong,\n",
      "X.,\n",
      "Zhang,\n",
      "C.,\n",
      "Ge,\n",
      "Y.,\n",
      "Mao,\n",
      "Y.,\n",
      "Gao,\n",
      "Y.,\n",
      "Chen, L., Lin, J., and Lou, D. (2023).\n",
      "C3:\n",
      "Zero-shot text-to-sql with chatgpt.\n",
      "arXiv preprint.\n",
      "https://doi.org/10.48550/arXiv.2307.07306.\n",
      "Floratou, A. et al. (2024). Nl2sql is a solved problem... not!\n",
      "In Conference on Innovative Data Systems Research.\n",
      "Gan, Y., Chen, X., Huang, Q., Purver, M., Woodward, J.,\n",
      "Xie, J., and Huang, P. (2021a). Towards robustness of\n",
      "text-to-sql models against synonym substitution. In\n",
      "Proceedings of the 59th Annual Meeting of the As-\n",
      "sociation for Computational Linguistics and the 11th\n",
      "International Joint Conference on Natural Language\n",
      "Processing, page 2505–2515. Association for Compu-\n",
      "tational Linguistics.\n",
      "Gan, Y., Chen, X., and Purver, M. (2021b).\n",
      "Exploring\n",
      "underexplored limitations of cross-domain text-to-sql\n",
      "generalization. In Moens, M.-F., Huang, X., Specia,\n",
      "L., and Yih, S., editors, Proceedings of the 2021 Con-\n",
      "ference on Empirical Methods in Natural Language\n",
      "Processing, page 8926–8931. Association for Compu-\n",
      "tational Linguistics.\n",
      "Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi,\n",
      "Y., Dai, Y., Sun, J., Guo, Q., Wang, M., and\n",
      "Wang, H. (2024). Retrieval-augmented generation for\n",
      "large language models: A survey.\n",
      "arXiv preprint.\n",
      "https://doi.org/10.48550/arXiv.2312.10997.\n",
      "Garc´ıa, G., Izquierdo, Y., Menendez, E., Dartayre, F.,\n",
      "and Casanova, M. (2017). Rdf keyword-based query\n",
      "technology meets a real-world dataset. In Proceed-\n",
      "ings of the 20th International Conference on Extend-\n",
      "ing Database Technology (EDBT), pages 656–667,\n",
      "Venice, Italy. OpenProceedings.org.\n",
      "Guo, C., Tian, Z., Tang, J., Li, S., Wen, Z., Wang, K., and\n",
      "Wang, T. (2024). Retrieval-augmented gpt-3.5-based\n",
      "text-to-sql framework with sample-aware prompting\n",
      "and dynamic revision chain. In Neural Information\n",
      "Processing, pages 341–356, Singapore. Springer Na-\n",
      "ture Singapore.\n",
      "Izquierdo, Y., Garc´ıa, G., Lemos, M., Novello, A., Nov-\n",
      "elli, B., Damasceno, C., Leme, L., and Casanova, M.\n",
      "(2021). A platform for keyword search and its appli-\n",
      "cation for covid-19 pandemic data. Journal of Infor-\n",
      "mation and Data Management, 12(5):521–535.\n",
      "Izquierdo, Y., Lemos, M., Oliveira, C., Novelli, B., Garc´ıa,\n",
      "G., Coelho, G., Feij´o, L., Coutinho, B., Santana, T.,\n",
      "Garcia, R., and Casanova, M. (2024). Busca360: A\n",
      "search application in the context of top-side asset in-\n",
      "tegrity management in the oil & gas industry. In Anais\n",
      "do XXXIX Simp´osio Brasileiro de Bancos de Dados,\n",
      "pages 104–116, Porto Alegre, RS, Brasil. SBC.\n",
      "Katsogiannis-Meimarakis, G. and Koutrika, G. (2023). A\n",
      "survey on deep learning approaches for text-to-sql.\n",
      "The VLDB Journal, 32(4):905–936.\n",
      "Kim, H., So, B.-H., Han, W.-S., and Lee, H. (2020). Natural\n",
      "language to sql: Where are we today?\n",
      "Proc. VLDB\n",
      "Endow., 13(10):1737–1750.\n",
      "Lei,\n",
      "F.\n",
      "et\n",
      "al.\n",
      "(2024).\n",
      "Spider\n",
      "2.0:\n",
      "Evaluat-\n",
      "ing\n",
      "language\n",
      "models\n",
      "on\n",
      "real-world\n",
      "enter-\n",
      "prise\n",
      "text-to-sql\n",
      "workflows.\n",
      "arXiv\n",
      "preprint.\n",
      "https://doi.org/10.48550/arXiv.2411.07763.\n",
      "Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin,\n",
      "V.,\n",
      "Goyal,\n",
      "N.,\n",
      "K¨uttler,\n",
      "H.,\n",
      "Lewis,\n",
      "M.,\n",
      "Yih,\n",
      "W.-t.,\n",
      "Rockt¨aschel,\n",
      "T.,\n",
      "Riedel,\n",
      "S.,\n",
      "and Kiela,\n",
      "D. (2020).\n",
      "Retrieval-augmented generation for\n",
      "knowledge-intensive nlp tasks.\n",
      "In Larochelle, H.,\n",
      "Ranzato, M., Hadsell, R., Balcan, M., and Lin, H., edi-\n",
      "tors, Advances in Neural Information Processing Sys-\n",
      "tems, volume 33, pages 9459–9474, Red Hook, NY,\n",
      "USA. Curran Associates, Inc.\n",
      "Li, J., Hui, B., Qu, G., Yang, J., Li, B., Li, B., Wang, B.,\n",
      "Qin, B., Geng, R., Huo, N., Zhou, X., Ma, C., Li, G.,\n",
      "Chang, K., Huang, F., Cheng, R., and Li, Y. (2024).\n",
      "Can llm already serve as a database interface? a big\n",
      "bench for large-scale database grounded text-to-sqls.\n",
      "In Proceedings of the 37th International Conference\n",
      "on Neural Information Processing Systems, NIPS ’23,\n",
      "Red Hook, NY, USA. Curran Associates Inc.\n",
      "Nascimento, E.R. Avila, C., Izquierdo, Y., Garc´ıa, G., Feij´o,\n",
      "L., Facina, M., M., L., and Casanova, M. (2025). On\n",
      "the text-to-sql task supported by database keyword\n",
      "search. In (Accepted to the 27th International Confer-\n",
      "ence on Enterprise Information Systems), Porto, Por-\n",
      "tugal.\n",
      "Nascimento, E., Garc´ıa, G., Feij´o, L., Victorio, W.,\n",
      "Izquierdo, Y., Oliveira, A., Coelho, G., M., L., Garcia,\n",
      "R., Leme, L., and Casanova, M. (2024a). Text-to-sql\n",
      "meets the real-world. In Proceedings of the 26th Inter-\n",
      "national Conference on Enterprise Information Sys-\n",
      "tems - Volume 1: ICEIS, pages 61–72, Set´ubal, Portu-\n",
      "gal. INSTICC, SciTePress.\n",
      "Nascimento, E., Izquierdo, Y., Garc´ıa, G., Coelho, G.,\n",
      "Feij´o, L., Lemos, M., Leme, L., and M.A., C.\n",
      "(2024b). My database user is a large language model.\n",
      "In Proceedings of the 26th International Confer-\n",
      "ence on Enterprise Information Systems - Volume 1:\n",
      "ICEIS, pages 800–806, Set´ubal, Portugal. INSTICC,\n",
      "SciTePress.\n",
      "Oliveira, A., Nascimento, E., Pinheiro, J., Avila, C., Coelho,\n",
      "G., Feij´o, L., Izquierdo, Y., Garc´ıa, G., Leme, L.,\n",
      "Lemos, M., and Casanova, M. (2025). Small, medium,\n",
      "and large language models for text-to-sql. In Maass,\n",
      "W., Han, H., Yasar, H., and Multari, N., editors, Con-\n",
      "ceptual Modeling, pages 276–294, Cham. Springer\n",
      "Nature Switzerland.\n",
      "Panda, S. and Gozluklu, B. (28 Feb 2024). Build a robust\n",
      "text-to-sql solution generating complex queries, self-\n",
      "correcting, and querying diverse data sources. AWS\n",
      "Machine Learning Blog.\n",
      "Pourreza, M. and Rafiei, D. (2024). Din-sql: decomposed\n",
      "in-context learning of text-to-sql with self-correction.\n",
      "In Proceedings of the 37th International Conference\n",
      "on Neural Information Processing Systems, NIPS ’23,\n",
      "Red Hook, NY, USA. Curran Associates Inc.\n",
      "Shi, L., Tang, Z., Zhang, N., Zhang, X., and Yang,\n",
      "Z. (2024).\n",
      "A survey on employing large lan-\n",
      "guage models for text-to-sql tasks.\n",
      "arXiv preprint.\n",
      "https://doi.org/10.48550/arXiv.2407.15186.\n",
      "Yu, T., Zhang, R., Yang, K., Yasunaga, M., Wang, D., Li,\n",
      "Z., Ma, J., Li, I., Yao, Q., Roman, S., Zhang, Z.,\n",
      "and Radev, D. (2018). Spider: A large-scale human-\n",
      "labeled dataset for complex and cross-domain seman-\n",
      "tic parsing and text-to-sql task. In Riloff, E., Chiang,\n",
      "D., Hockenmaier, J., and Tsujii, J., editors, Proc. 2018\n",
      "Conference on Empirical Methods in Natural Lan-\n",
      "guage Processing, pages 3911–3921, Brussels, Bel-\n",
      "gium. Association for Computational Linguistics.\n",
      "Table 4: Sample NL simple questions and their SQL golden standard (anonymized).\n",
      "Table 5: Sample NL medium questions and their SQL golden standard (anonymized).\n",
      "Table 6: Sample complex NL questions and their SQL golden standard (anonymized).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "pdf_path = \"test1.pdf\"\n",
    "references = extract_references(pdf_path)\n",
    "\n",
    "# Print or save the extracted references\n",
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
