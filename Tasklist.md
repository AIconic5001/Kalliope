
## Data Engineering Task List for Kalliope - Nhat Phan 

1. **Specify data sources** for academic papers, including public databases and APIs to ensure comprehensive coverage of relevant literature.
2. **Design ETL processes** to extract, cleanse, and transform academic paper data, ensuring consistency, accuracy, and deduplication before storage in the database.
3. **Develop Python-based pipelines** using tools like PySpark and Pandas for scalable processing of large datasets to handle metadata, citations, and NLP-generated summaries.
4. **Obtain real-time updates** from selected paper repositories and ensure that the data ingestion process can handle ongoing additions and changes in academic publications.
5. **Test and validate database queries** to ensure that users receive accurate and timely recommendations, related papers, and synopses in line with project documentation.


## AI Engineering Task List for Kalliope - Huy Le:

1. **Compile** list of tags and keywords from research papers using chatGPT
2. **Find** suitable GPT model to fine-tune
3. **Develop** appropriate fine-tune method to achieve accurate generation of research paper synopsis
4. **Test** generation of new GPT model
5. **Structure** dataset containing acquired generated data

## Software Engineer Task List for Kalliope - Huu Quang Nhat Nguyen:
1. **Design UI**: Create wireframes and mockups of the app's layout.
2. **Set up Project Structure**: Initialize the project with a front-end framework (e.g., React, Vue, or Angular).
3. **Implement responsive UI**: Develop a responsive layout
4. **Build Core Features and Components**: Create essential UI components (e.g., buttons, forms, navigation bars) and integrate functionality (e.g., state management).
5. **Integrate API or Backend Services**: Connect the front-end with the backend API for data fetching and manipulation.

## Data Analyzing/ Data Engineering Task List for Kalliope - Du Nguyen:
1. **Design** the input module to allow users to upload research papers in various formats (PDF, DOCX) for processing.
2. **Validate** the uploaded document's structure and content to ensure it meets the required format for accurate processing and date extraction.
3. **Develop** an NLP-based system to extract key information from the uploaded papers, such as title, authors, abstract, keywords, and publication date.
4. **Implement** a visualization system to display the recency of referenced papers, using options like a timeline, bar chart, or scatter plot, allowing users to quickly understand the publication dates.
5. **Test the** module to ensure accurate reading, processing, and visualization of papers, validating that all features, including date-based visualizations, work as expected.
